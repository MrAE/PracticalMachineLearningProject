---
title: "Data Science Specialization: Practical Machine Learning"
author: "Jesse Leigh Patsolic"
output: 
  html_document:
    keep_md: true
---

```{r knitCode, eval=FALSE, echo=FALSE}
require(knitr); rm(list=ls()); knit2html("Proj.Rmd")
```

## Objective 


The goal of this project is to use the data provided by 
[groupware](http://groupware.les.inf.puc-rio.br/har) to create a 
model that will predict the type of exercise that each subject is performing.

## Data Preparation 

First are the libraries required to run this code.
The training and testing data are loaded from the links given on the
project webpage and stored in appropriately named objects.
The first few columns denote subject name and various timestamps which
are unnecessary for the prediction and will be removed.

```{r loadData}
require(caret)
require(rattle)
require(ggplot2)

if(!file.exists("data")){
    dir.create("data")
    trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download.file(trainURL, destfile="./data/training.csv", method="curl")
    download.file(testURL, destfile="./data/testing.csv", method="curl")
    }

training0 <- read.csv("data/training.csv")[,-c(1:5)]
testing0  <- read.csv("data/testing.csv")[,-c(1:5)]
```

In surveying the data I have noticed there are some entries with
`#DIV/0!` values.  I will convert these to `NA` in an attempt to clean 
the data before modeling.  The columns that have these values have been
read in as factor variables; this must be corrected as well.  
Some columns have more `NA` values than actual 

```{r cleanup}
training1 <- replace(training0, 
                     which(training0 == "#DIV/0!", arr.ind=TRUE),
                     NA)

i <- sapply(training1, is.factor); i[c("classe")] <- !i[c("classe")]
training1[i] <- lapply(training1[i], as.numeric)

l0 <- lapply(training1, function(x) all(!is.na(x)))

nl0 <- names(l0[l0 == TRUE])

training1 <- training1[,nl0]
```

The cleaned data set will be subset further into `train` and `test` sets
for model creation.

Now the cleaned training data will be subset further

```{r trainSelection, eval=TRUE}
set.seed(648)                          # seed for reproducibility
inTrain <- createDataPartition(y=training1$classe,p=0.6,list=FALSE)
train1 <- training1[inTrain,]
test1 <- training1[-inTrain,]
```



```{r model, eval=TRUE}
#modFitGLM   <- train(classe ~ ., method="glm", data=train1)
#modFitRpart <- train(classe ~ ., method="rpart", data=train1)
modFitRF <- train(classe ~ ., method="rf", data=train1, prox=TRUE)
print(modFit$finalModel)
```

```{r pred, eval=FALSE}
modPred <- predict(modFitRF, newdata=test1)
table(test1$classe == modPred)
```


















```{r print,, echo=FALSE, eval=FALSE}
## Example code to generate submission files.
answers = rep("A", 20)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}


pml_write_files(answers)
```
